{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Creating Cutting-Edge Geodemographic Classifications from Scratch in Python\"\n",
    "author: \"Owen Goodwin\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-location: left\n",
    "    toc-float: true\n",
    "    theme: cosmo\n",
    "    highlight-style: github\n",
    "    reference-location: margin\n",
    "    citation-location: margin\n",
    "    margin-references: true\n",
    "\n",
    "bibliography: bibliography.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Content\n",
    "\n",
    "This notebook contains the full workflow for producing a geodemographic classification from scratch in python using k-means clustering. \n",
    "\n",
    "* **Data Access and Processing:**\n",
    "    * Access UK Census data and process using Pandas.\n",
    "    * Select a specific region of interest (e.g., Liverpool City Region, Greater Manchester, Greater London).\n",
    "\n",
    "* **Census Data Analysis and Variable selection:**\n",
    "    * Select relevant Census variables for clustering.\n",
    "    * Standardise variables.\n",
    "    * Perform correlation & variance analysis to identify potentially redundant variables.\n",
    "    * Alternative variable selection methods (e.g., PCA, Autoencoders).\n",
    "\n",
    "* **Clustering:**\n",
    "    * Determine optimal number of clusters using Clustergrams.\n",
    "    * Apply K-Means clustering to classify areas based on selected variables.\n",
    "    * Perform top-down hierarchical clustering to divide clusters into subgroups.\n",
    "    \n",
    "* **Analytical Techniques:**\n",
    "    * Use UMAP (Uniform Manifold Approximation and Projection) to visualise high-dimensional embeddings in 2D.\n",
    "\n",
    "* **Visualisation and Communication:**\n",
    "    * Visualise clusters and subclusters using Kepler.gl for interactive mapping.\n",
    "    * Explore cluster characteristics using summary statistics and index scores.\n",
    "    * Export results to various formats (GeoPackage, Parquet) for use in GIS software.\n",
    "    \n",
    "* **Cluster Naming with LLMs:**\n",
    "    * Use Large Language Models (LLMs) to generate descriptive names and summaries for clusters based on their characteristics.\n",
    "\n",
    "The code used to generate this notebook is available on [GitHub](https://github.com/ogoodwin505/GeoDem_CartoWorkshop2025).\n",
    "Instructions for setting up the environment and downloading the data are provided in the [README](README.md) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Geodemographics?\n",
    "\n",
    "Geodemographics are a method of classifying geographic areas based on the characteristics of their populations. It involves grouping areas with similar demographic, socio-economic, and lifestyle attributes into distinct categories or clusters. These classifications help in understanding the spatial distribution of different population segments and are widely used in various fields such as marketing, urban planning, public health, and social research. \n",
    "For more information on geodemographics in the UK and the US see: [@geodemhistory].\n",
    "\n",
    "\n",
    "Geodemographic classifications are typically created using statistical techniques such as cluster analysis, in particular k-means clustering. That is the method we will use in this workshop.\n",
    "\n",
    "\n",
    "## Install Required Packages in Colab\n",
    "If you are using Google Colab, you will need to install the required packages in the Colab environment. You can do this by uncommenting and running the following code cell in the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas geopandas pyarrow scikit-learn clustergram umap-learn seaborn plotly matplotlib numpy keplergl openai"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Import the necessary libraries and packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import KMeans\n",
    "from clustergram import Clustergram\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns\n",
    "import openai\n",
    "import json\n",
    "\n",
    "#set a  random seed for reproducibility\n",
    "random_seed = 507\n",
    "\n",
    "#check that outputs directories exists (if not create it), this is important if you are running the notebook in colab\n",
    "\n",
    "if not os.path.exists('outputs'):\n",
    "    os.makedirs('outputs')\n",
    "if not os.path.exists('outputs/maps'):\n",
    "    os.makedirs('outputs/maps')\n",
    "if not os.path.exists('outputs/plots'):\n",
    "    os.makedirs('outputs/plots')\n",
    "if not os.path.exists('outputs/subclusters'):\n",
    "    os.makedirs('outputs/subclusters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Set global font sizes (affects titles, labels, ticks, etc.)\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 7,   # subplot titles\n",
    "    \"axes.labelsize\": 8,   # x/y labels\n",
    "    \"xtick.labelsize\": 6,  # x tick labels\n",
    "    \"ytick.labelsize\": 6,  # y tick labels\n",
    "    \"legend.fontsize\": 6,  # legend\n",
    "    \"figure.figsize\": (8, 6)  # default figure size\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Retrieving and Preparing Data\n",
    "We will be using Census data from all four UK nations, which are available openly from the respective national statistics agencies (listed below). \n",
    "For this workshop, we will utilise a subset of Census variables that have been unified across the four nations. These variables were used to produce a UK-wide Output Area Classification (OAC) in 2021 [@2021oac].\n",
    "We will also need boundary data for the Output Areas (OAs).\n",
    "All the data required can be downloaded from the Geographic Data Service Website [LINK], place file `input_data.zip` in the same directory as the notebook and it will be unzipped to a folder called `input_data`.\n",
    "\n",
    "Original Data Sources:\n",
    "\n",
    "1. **ONS Census 2021** (England & Wales):  \n",
    "   - [ONS Data Service](https://www.ons.gov.uk/)\n",
    "\n",
    "\n",
    "2. **NRS Census 2022** (Scotland):  \n",
    "   - [Scotland's Census](https://www.scotlandscensus.gov.uk/)\n",
    "\n",
    "\n",
    "3. **NISRA Census 2021** (Northern Ireland):  \n",
    "   - [NISRA Website](https://www.nisra.gov.uk/)\n",
    "\n",
    "   \n",
    "4. **ONS Geoportal** for boundaries and shapefiles, including clipped EW, Scotland, and Northern Ireland geographies.\n",
    "   - [ONS Geoportal](https://geoportal.statistics.gov.uk/)\n",
    "\n",
    "\n",
    "### Output Areas\n",
    "Output Areas (OAs) [@oacreation], called data zones in northern ireland and small areas in Scotland, are the smallest geographical units available openly in the UK Census. They are designed to have similar population sizes and are used to report Census data. Each OA typically contains around 100-200 households. These are the base geographical units used in this classification.\n",
    "\n",
    "![](images/OAexample_new.png){fig-align=\"center\" width=\"85%\"}\n",
    "\n",
    "### Spatial Standardisation\n",
    "\n",
    "The data here has been normalised by the total population of each OA to give a percentage. This is important as OAs can vary in population size, and using raw counts would bias the clustering towards more populous areas.\n",
    "We also include the population density of each OA (population / area in sqkm) as a variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the data if not already done\n",
    "if not os.path.exists('input_data'):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('input_data_1.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the census data\n",
    "variable_df = pd.read_parquet(\"input_data/uk_census_data.parquet\")\n",
    "#round to 2 decimal places\n",
    "variable_df = variable_df.round(2)\n",
    "#look at the shape of the dataset\n",
    "print(f\"Input data shape: {variable_df.shape}\")\n",
    "#look at the first few rows of the dataset\n",
    "variable_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short descriptions of the variables used in this example are found in the file `census_variable_lookup.csv`. The full variable descriptions can be found in the [2021 Census User Guide](https://www.ons.gov.uk/census/censustransformationprogramme/2021census/2021censususerguide).\n",
    "\n",
    "These variables have been selected to provide a broad overview of demographic, socio-economic, and housing characteristics. They cover aspects such as age distribution, household composition, housing type, housing tenure, employment status and education levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the lookup file which contains variable descriptions.\n",
    "var_lookup = pd.read_csv(\"input_data/census_variable_lookup.csv\")[[\"No.\",\"Variable_Name\",\"Domain\"]]\n",
    "var_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Data\n",
    "\n",
    "We can plot the distribution of all the variables to get a sense of their distributions. Many of the variables are highly skewed, which is common for Census data. Skewed variables can be problematic for Geodemographics because they cause distance metrics to be dominated by extreme values so effect the quality of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas histogram plotting function with seaborn aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "nrows = int(np.ceil(len(variable_df.columns) / 3))\n",
    "\n",
    "variable_df_withnames = variable_df.copy()\n",
    "variable_df_withnames.columns = var_lookup['Variable_Name'].values[:58]\n",
    "variable_df_withnames.hist(bins=30, figsize=(7.5, nrows*1.5), edgecolor='black', layout=(nrows, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Data\n",
    "\n",
    "We will also need the Output Area boundaries to map the results. The file used here is a GeoPackage containing the 2021 Output Area boundaries for the whole of the UK, clipped to the extent of England and Wales, Scotland, and Northern Ireland. The file has been created by joining the original files for each nation downloaded from the ONS Geoportal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------\n",
    "# Import spatial data\n",
    "#---------\n",
    "OA_Boundaries = gpd.read_file(\"input_data/OA_2021_22_Boundaries.gpkg\").set_index('OA')\n",
    "#---------\n",
    "# Load Local Authority District (LAD) for region selection\n",
    "#---------\n",
    "LAD_Boundaries = gpd.read_file(\"input_data/Local_Authority_Districts_December_2022_UK_BGC_V2_5759908710055972638.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Region\n",
    "For this workshop, we will focus on a specific region of the UK to keep the analysis manageable. \n",
    "\n",
    "Focusing on a specific region allows us to create a more detailed and relevant geodemographic classification for that area, capturing local nuances and characteristics that may be lost in a broader national classification. For example, a [London specific OAC](https://data.geods.ac.uk/dataset/london-oac) was developed as London has a drastically different demographic composition to the rest of the United Kingdom [@loac]. \n",
    "\n",
    "By default we will use the Output Areas within the Liverpool City Region covering the city of liverpool and its surrounding areas. This region is prodominently urban and has a diverse population, making it an interesting case study for geodemographic classification.\n",
    "If running this notebook on your own machine, you can change the region of study from the selection below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region definitions (LAD22CD codes)\n",
    "region_lads = {\n",
    "    \"Greater Manchester\": [\n",
    "        \"E08000001\",\"E08000002\",\"E08000003\",\"E08000004\",\"E08000005\",\n",
    "        \"E08000006\",\"E08000007\",\"E08000008\",\"E08000009\",\"E08000010\"\n",
    "    ],\n",
    "    \"Liverpool City Region\": [\n",
    "        \"E06000006\",\"E08000011\",\"E08000012\",\"E08000013\",\"E08000014\",\"E08000015\"\n",
    "    ],\n",
    "    \"Greater London\": [\n",
    "        \"E09000001\",\"E09000002\",\"E09000003\",\"E09000004\",\"E09000005\",\n",
    "        \"E09000006\",\"E09000007\",\"E09000008\",\"E09000009\",\"E09000010\",\n",
    "        \"E09000011\",\"E09000012\",\"E09000013\",\"E09000014\",\"E09000015\",\n",
    "        \"E09000016\",\"E09000017\",\"E09000018\",\"E09000019\",\"E09000020\",\n",
    "        \"E09000021\",\"E09000022\",\"E09000023\",\"E09000024\",\"E09000025\",\n",
    "        \"E09000026\",\"E09000027\",\"E09000028\",\"E09000029\",\"E09000030\",\n",
    "        \"E09000031\",\"E09000032\",\"E09000033\"\n",
    "    ],\n",
    "    \"Scotland\": [\n",
    "        \"S12000005\",\"S12000006\",\"S12000008\",\"S12000010\",\"S12000011\",\n",
    "        \"S12000013\",\"S12000014\",\"S12000017\",\"S12000018\",\"S12000019\",\n",
    "        \"S12000020\",\"S12000021\",\"S12000023\",\"S12000026\",\"S12000027\",\n",
    "        \"S12000028\",\"S12000029\",\"S12000030\",\"S12000033\",\"S12000034\",\n",
    "        \"S12000035\",\"S12000036\",\"S12000038\",\"S12000039\",\"S12000040\",\n",
    "        \"S12000041\",\"S12000042\",\"S12000045\",\"S12000047\",\"S12000048\",\n",
    "        \"S12000049\",\"S12000050\"\n",
    "    ],\n",
    "    \"Northern Ireland\": [\n",
    "        \"N09000001\",\"N09000002\",\"N09000003\",\"N09000004\",\"N09000005\",\n",
    "        \"N09000006\",\"N09000007\",\"N09000008\",\"N09000009\",\"N09000010\",\n",
    "        \"N09000011\"\n",
    "    ],\n",
    "    \"Wales\": [\n",
    "        \"W06000001\",\"W06000002\",\"W06000003\",\"W06000004\",\"W06000005\",\n",
    "        \"W06000006\",\"W06000007\",\"W06000008\",\"W06000009\",\"W06000010\",\n",
    "        \"W06000011\",\"W06000012\",\"W06000013\",\"W06000014\",\"W06000015\",\n",
    "        \"W06000016\",\"W06000017\",\"W06000018\",\"W06000019\",\"W06000020\",\n",
    "        \"W06000021\",\"W06000022\",\"W06000023\",\"W06000024\"\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the region of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose region from the list above by uncommenting the relevant line\n",
    "lad_codes = region_lads[\"Liverpool City Region\"]\n",
    "# #or eg:\n",
    "# lad_codes = region_lads[\"Scotland\"]\n",
    "\n",
    "# Spatial join to filter only intersecting OAs\n",
    "oas_region = gpd.sjoin(OA_Boundaries, LAD_Boundaries[LAD_Boundaries[\"LAD22CD\"].isin(lad_codes)], predicate=\"intersects\")\n",
    "\n",
    "# --- Merge OA polygons with your variable data keeping only those with matching OAs in the region\n",
    "oas_region_vars = oas_region.join(variable_df, how=\"inner\")\n",
    "\n",
    "# #keep only OAs in our region\n",
    "variable_df_region=variable_df.loc[variable_df.index.isin(oas_region.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the Area\n",
    "We will use Kepler.gl to visualise the Output Areas in our selected region. Kepler.gl is an open-source geospatial analysis tool that allows for interactive mapping and visualisation of large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "#code to enable kepler in colab\n",
    "from IPython.display import Javascript\n",
    "display(Javascript('''\n",
    "  google.colab.widgets.installCustomManager('https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/6a14374f468a145a/manager.min.js');\n",
    "'''))\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "region_geom = unary_union(\n",
    "    LAD_Boundaries.loc[LAD_Boundaries[\"LAD22CD\"].isin(lad_codes), \"geometry\"]\n",
    ")\n",
    "region_centroid = region_geom.centroid\n",
    "centroid_ll = gpd.GeoSeries([region_centroid], crs=LAD_Boundaries.crs).to_crs(epsg=4326).iloc[0]\n",
    "centroid_lat, centroid_lon = centroid_ll.y, centroid_ll.x\n",
    "\n",
    "# --- Quick Kepler map ---\n",
    "area_map_ = KeplerGl(\n",
    "    height=600,\n",
    "    config={\n",
    "        \"version\": \"v1\",\n",
    "        \"config\": {\n",
    "            \"mapState\": {\n",
    "               'latitude': centroid_lat,\n",
    "                'longitude': centroid_lon,\n",
    "                \"zoom\": 9,\n",
    "                \"pitch\": 0,\n",
    "                \"bearing\": 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "# Add your layer\n",
    "area_map_.add_data(data=oas_region_vars)\n",
    "# If you want to export to a standalone HTML:\n",
    "area_map_.save_to_html(file_name=\"outputs/maps/region_oas_map.html\")\n",
    "# Show inside Jupyter\n",
    "display(area_map_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"outputs/maps/region_oas_map.html\" width=\"100%\" height=\"650\" style=\"border:none;\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform and Standardise Variables\n",
    "\n",
    "Before applying clustering algorithms, it is important to transform and standardise the data to ensure that all variables contribute equally to the analysis.\n",
    "\n",
    "The function below applies two transformations to a dataframe (applied column-wise):\n",
    "\n",
    "1. **Inverse Hyperbolic Sine (IHS) transform**  \n",
    "2. **Min–Max scaling to [0, 1]**\n",
    "\n",
    "### Mathematical definitions\n",
    "\n",
    "**Inverse hyperbolic sine (IHS, a.k.a. arcsinh):**  \n",
    "- Similar to a log transform but works with zero and negative values.  \n",
    "- Helps stabilise variance and make skewed distributions more normal-like.  \n",
    "\n",
    "$$\n",
    "\\mathrm{arcsinh}(x) = \\ln\\!\\big(x + \\sqrt{x^{2}+1}\\big)\n",
    "$$\n",
    "\n",
    "**Properties:**\n",
    "- For large \\(|x|\\):  \n",
    "  $$\n",
    "  \\mathrm{arcsinh}(x) \\approx \\ln(2|x|)\n",
    "  $$\n",
    "  (behaves like log).  \n",
    "\n",
    "- Near \\(0\\):  \n",
    "  $$\n",
    "  \\mathrm{arcsinh}(x) \\approx x\n",
    "  $$\n",
    "\n",
    " \n",
    "\n",
    "**Min–Max scaling (applied per column after IHS):**\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n",
    "$$\n",
    "\n",
    "- Rescales all values into the range \\([0, 1]\\).  \n",
    "- Useful for comparing variables with different units/scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_standardise_data(df):\n",
    "    \"\"\"Apply inverse hyperbolic sine transform, to account for non-normality\n",
    "    and then range standardise using min-max scaling to the dataframe.\"\"\"\n",
    "    df = np.arcsinh(df)\n",
    "    denom = df.max() - df.min()\n",
    "    df = (df - df.min()) / denom.replace(0, 1)  # prevent divide-by-zero\n",
    "    return df\n",
    "\n",
    "# Transform the input data\n",
    "transformed_variable_df = transform_and_standardise_data(variable_df_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection\n",
    "In geodemographics, **variable selection** is crucial to turn large datasets (like the UK Census) with 100s of variables into meaningful clusters.  \n",
    "The nature of clustering means the high-dimensional space can be sparse and noisy, so reducing the number of variables helps improve cluster quality and interpretability.\n",
    "\n",
    "Key points:  \n",
    "- **Intention** – variables depend on the purpose of the geodem (e.g. retail vs. health).  \n",
    "- **Correlation** – drop highly correlated variables to avoid redundancy.  \n",
    "- **Variance** – keep variables that vary across places (so they can distinguish areas).  \n",
    "- **Expert choice** – ensure selected variables are socially meaningful.  \n",
    "\n",
    "Here we are using a **broad, pre-selected dataset** which was used for the UK OAC 2021 classification. So we expect the variables to be broadly suitable for our region of interest.\n",
    "\n",
    "New methods include:  \n",
    "- **Automated variable selection** [@pcavarselect] – uses statistical procedure to determine a subset of variables which produce the best clustering results.  \n",
    "- **Autoencoders** – Use neural networks to compress all variables into a smaller set of features, while preserving the most important patterns.\n",
    "\n",
    "## Correlation & Variance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| out.width: \"100%\"\n",
    "transformed_variable_df_withnames = transformed_variable_df.copy()\n",
    "transformed_variable_df_withnames.columns = [var_lookup.set_index(\"No.\")[\"Variable_Name\"].to_dict().get(col, col) for col in transformed_variable_df.columns]\n",
    "\n",
    "# --- Correlation Check ---\n",
    "corr_matrix = transformed_variable_df_withnames.corr()\n",
    "# --- Interactive heatmap with Plotly ---\n",
    "fig = px.imshow(\n",
    "    corr_matrix.values,\n",
    "    color_continuous_scale=\"RdBu_r\",\n",
    "    zmin=-1, zmax=1,\n",
    "    title=\"Correlation Heatmap\",\n",
    "    x=corr_matrix.columns,\n",
    "    y=corr_matrix.columns,\n",
    ")\n",
    "# Add hover names for tooltips\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<b>%{x}</b> vs <b>%{y}</b><br>Correlation: %{z:.3f}<extra></extra>\",\n",
    ")\n",
    "# Hide x/y tick labels but keep tooltips\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()\n",
    "\n",
    "# --- Find highly correlated pairs (print each pair twice) ---\n",
    "cols = corr_matrix.columns\n",
    "# consider only upper triangle to get unique unordered pairs (i < j)\n",
    "upper_mask = np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1)\n",
    "# build mask for correlations above 0.95 (and exclude perfect 1.0)\n",
    "corr_threshold = 0.95\n",
    "corr_vals = corr_matrix.values\n",
    "# consider only upper triangle unique pairs (i < j) and print each once once\n",
    "mask = ((corr_vals > corr_threshold) & upper_mask)\n",
    "\n",
    "pairs = np.column_stack(np.where(mask))\n",
    "for i, j in pairs:\n",
    "    col_i, col_j = cols[i], cols[j]\n",
    "    val = corr_matrix.iat[i, j]\n",
    "    print(f\"High correlation between {col_i} and {col_j}: {val:.3f}\")\n",
    "\n",
    "# --- Variance Check ---\n",
    "variances = transformed_variable_df_withnames.var()\n",
    "#plot the variances\n",
    "plt.figure(figsize=(8, 5))\n",
    "variances.sort_values().plot(kind='bar')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Variance of Each Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Variables\n",
    "If we want to remove any variables we can do so here. \n",
    "This could be based on the analysis above or to tailor the classification to a specific purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_vars = ['v02', 'v04']  # Replace with actual variable names to drop\n",
    "drop_vars = [] # Example: No variables to drop\n",
    "# for northern ireland #bangladeshi ethnicity now removed as no variation as no bangladeshi in northern ireland\n",
    "# drop_vars = ['v12'] \n",
    "\n",
    "cleaned_variable_df = transformed_variable_df.drop(columns=drop_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "K-means clustering is the most commonly used clustering algorithm for geodemographic classification.\n",
    "It partitions a dataset into *k* groups (clusters), where each observation belongs to the cluster with the nearest mean (centroid). The algorithm iteratively updates cluster assignments and centroids until convergence.\n",
    "\n",
    "**How it works (simplified):**\n",
    "\n",
    "1. Choose the number of clusters (*k*).  \n",
    "2. Initialise *k* centroids (usually at random points in the data space).\n",
    "3. Assign each data point to the nearest centroid.  \n",
    "4. Update centroids as the mean of the points in each cluster.  \n",
    "5. Repeat steps 3–4 until assignments no longer change (or improvement is below a threshold).\n",
    "\n",
    "**Strengths:**\n",
    "- Simple and computationally efficient.  \n",
    "- Works well when clusters are roughly spherical and similar in size.  \n",
    "\n",
    "**Limitations:**\n",
    "- Requires specifying *k* in advance.  \n",
    "- Sensitive to outliers and scaling of features.  \n",
    "- Assumes clusters are convex^[A set is convex if, for any two points in the set, the straight line between them lies entirely within the set.] and isotropic^[Having uniform properties in all directions]; k‑means effectively assumes clusters are roughly spherical with similar variance in every direction, which may not hold in real data. \n",
    "\n",
    "More details and examples can be found here: [Scikit-learn: K-Means](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
    "\n",
    "\n",
    "## Choosing the Number of Clusters (k) - Clustergrams\n",
    "\n",
    "When using k-means clustering, one of the key decisions is selecting the optimal number of clusters (k). This choice can significantly impact the quality and interpretability of the resulting geodemographic classification.\n",
    "Key considerations when choosing k:\n",
    "\n",
    "- Each cluster be as homogeneous as possible.\n",
    "- Each cluster should be as distinct from the others as possible.\n",
    "- The clusters should be as evenly sized as possible.\n",
    "\n",
    "Clustergrams [@clustergram] are visualisation technique that shows how cluster assignments change as you increase the number of clusters (k). This helps you to understand the structure in very high-dimensional space in the following ways:\n",
    "\n",
    "- **Cluster separation**: Helps you to determine the right number of clusters by visualising how cleanly clusters separate  \n",
    "- **Cluster stability**: Shows which clusters persist across different k values (stable long lines) vs. those which are artifacts of over-clustering (short, erratic lines)  \n",
    "- **Split patterns**: Reveals the natural hierarchy in the data by showing how clusters subdivide  \n",
    "\n",
    "\n",
    "Further guidance on interpreting clustergrams and choosing the number of clusters can be found here: [Clustergram](https://clustergram.readthedocs.io/en/stable/notebooks/introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since k-means is sensitive to initialization, `n_init` determines the number of \n",
    "# times the algorithm runs with different centroid seeds. The final result is the \n",
    "# best outcome based on inertia/WCSS (within-cluster sum of squares).\n",
    "n_init = 100  # Use a low value for quick testing, increase (~100) for final results\n",
    "cgram = Clustergram(range(1, 10), n_init=n_init, random_state=random_seed,verbose=False)  # Initialize clustergram model\n",
    "cgram.fit(cleaned_variable_df)  # Fit model to data\n",
    "cgram.plot()  # Generate plot\n",
    "plt.savefig(\"outputs/plots/supergroup_clustergram.png\")  # Save figure\n",
    "plt.show()  # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the number of clusters (k) based on the clustergram above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters (K). Choose K based on the clustergram plot.\n",
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_clusters (int): The number of clusters (K) to create.\n",
    "# n_init (int): Number of times the K-means algorithm runs with different initial \n",
    "#                 centroid seeds. The best result based on inertia/WCSS is chosen. \n",
    "#                 A higher value (e.g., ~1000) is recommended for final results, \n",
    "#                 but a lower value can be used for testing.\n",
    "\n",
    "\n",
    "n_init = 1000 # Use a low value for quick testing, increase (~100) for final results\n",
    "output_filepath = \"outputs/supergroups_clusteroutput.csv\"\n",
    "# Initialize the K-means model\n",
    "kmeans_model = KMeans(n_clusters=num_clusters,init=\"random\", random_state=random_seed, n_init=n_init)\n",
    "# Fit the model and assign clusters to a new dataframe which is a copy of the input data\n",
    "supergrouped_variable_df = cleaned_variable_df.copy()\n",
    "supergrouped_variable_df['cluster'] = kmeans_model.fit_predict(cleaned_variable_df)\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "# Save the cluster assignments to a CSV file\n",
    "supergrouped_variable_df[['cluster']].to_csv(output_filepath)\n",
    "# Map numeric labels to letters\n",
    "label_map = {i: chr(65 + i) for i in range(num_clusters)}  # 0->A, 1->B, etc.\n",
    "supergrouped_variable_df['cluster'] = supergrouped_variable_df['cluster'].map(label_map)\n",
    "#verify the output\n",
    "supergrouped_variable_df[\"cluster\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the Clusters\n",
    "We can visualise the clusters on a map to see their spatial distribution. This can help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| echo: false\n",
    "#code to enable kepler in colab\n",
    "from IPython.display import Javascript\n",
    "display(Javascript('''\n",
    "  google.colab.widgets.installCustomManager('https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/6a14374f468a145a/manager.min.js');\n",
    "'''))\n",
    "\n",
    "# Custom cluster colours for up to 10 clusters\n",
    "colours = {\n",
    "    \"A\": '#8dd3c7',\n",
    "    \"B\": '#ffffb3',\n",
    "    \"C\": '#bebada',\n",
    "    \"D\": '#fb8072',\n",
    "    \"E\": '#fdb462',\n",
    "    \"F\": \"#235477\",\n",
    "    \"G\": '#fccde5',\n",
    "    \"H\": '#d9d9d9',\n",
    "    \"I\": '#bc80bd',\n",
    "    \"J\": '#ccebc5'\n",
    "}\n",
    "\n",
    "sorted_clusters = sorted(colours.keys())\n",
    "colour_list = [colours[k] for k in sorted_clusters]\n",
    "\n",
    "# #append geometry column from oas_region to supergrouped_variable_df to make a geodataframe\n",
    "gdf = oas_region.merge(supergrouped_variable_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Config for map\n",
    "config = {\n",
    "    \"version\": \"v1\",\n",
    "    \"config\": {\n",
    "        \"visState\": {\n",
    "            \"filters\": [],\n",
    "            \"layers\": [\n",
    "                {\n",
    "                    \"id\": \"clusters_layer\",\n",
    "                    \"type\": \"geojson\",   # polygon layer\n",
    "                    \"config\": {\n",
    "                        \"dataId\": \"clusters\",\n",
    "                        \"label\": \"Clusters\",\n",
    "                        'columns': {'geojson': 'geometry'},\n",
    "                        \"color\": [130, 154, 227],\n",
    "                        \"highlightColor\": [252, 242, 26, 255],\n",
    "                        \"isVisible\": True,\n",
    "                        \"visConfig\": {\n",
    "                            \"opacity\": 0.8,\n",
    "                            \"thickness\": 0,\n",
    "                            \"strokeColor\": None,\n",
    "                            \"colorRange\": {\n",
    "                                \"name\": \"Custom\",\n",
    "                                \"type\": \"qualitative\",\n",
    "                                \"category\": \"Custom\",\n",
    "                                \"colors\": colour_list\n",
    "                            },\n",
    "                            \"filled\": True\n",
    "                        },\n",
    "                        \"hidden\": False,\n",
    "                        \"textLabel\": []\n",
    "                    },\n",
    "                    \"visualChannels\": {\n",
    "                        \"colorField\": {\"name\": \"cluster\", \"type\": \"string\"},\n",
    "                        \"colorScale\": \"ordinal\",\n",
    "                        \"strokeColorField\": None,\n",
    "                        \"strokeColorScale\": \"quantile\",\n",
    "                        \"sizeField\": None,\n",
    "                        \"sizeScale\": \"linear\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"effects\": [],\n",
    "            \"interactionConfig\": {\n",
    "                \"tooltip\": {\n",
    "                    \"fieldsToShow\": {\n",
    "                        \"clusters\": [\n",
    "                            {\"name\": \"cluster\", \"format\": None}\n",
    "                        ]\n",
    "                    },\n",
    "                    \"enabled\": True\n",
    "                },\n",
    "                \"legend\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"active\": True\n",
    "                }\n",
    "            },\n",
    "\n",
    "            \"layerBlending\": \"normal\"\n",
    "        },\n",
    "        \"mapState\": {\n",
    "            \"bearing\": 0,\n",
    "            \"dragRotate\": False,\n",
    "               'latitude': centroid_lat,\n",
    "            'longitude': centroid_lon,\n",
    "            \"pitch\": 0,\n",
    "            \"zoom\": 9,\n",
    "            \"isSplit\": False\n",
    "        },\n",
    "        \"mapStyle\": {\n",
    "            \"styleType\": \"dark-matter\",\n",
    "            \"topLayerGroups\": {\n",
    "                \"water\": True,\n",
    "                \"building\": True\n",
    "            },\n",
    "            \"visibleLayerGroups\": {\n",
    "                \"label\": True,\n",
    "                \"road\": True,\n",
    "                \"border\": False,\n",
    "                \"building\": True,\n",
    "                \"water\": True,\n",
    "                \"land\": True,\n",
    "                \"3d building\": False\n",
    "            },\n",
    "            \"mapStyles\": {\n",
    "                \"dark-matter\": {\n",
    "                    \"id\": \"dark-matter\",\n",
    "                    \"label\": \"Carto Dark Matter\",\n",
    "                    \"url\": \"https://basemaps.cartocdn.com/gl/dark-matter-gl-style/style.json\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Show in Kepler\n",
    "map_with_basemap = KeplerGl(data={\"clusters\":gdf}, config=config, height=600)\n",
    "map_with_basemap.save_to_html(file_name=\"outputs/maps/cluster_map.html\")\n",
    "map_with_basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"outputs/maps/cluster_map.html\" width=\"100%\" height=\"650\" style=\"border:none;\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP Visualisation\n",
    "\n",
    "We can use UMAP (Uniform Manifold Approximation and Projection) [@umap] to visualise the high-dimensional Census data in 2D. UMAP is a dimensionality reduction technique that preserves both local and global structure in the data, making it well-suited for visualising complex datasets like Census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features = all columns except the cluster label\n",
    "features = [c for c in supergrouped_variable_df.columns if c != 'cluster']\n",
    "# Extract features and labels  (transformed)\n",
    "X = supergrouped_variable_df[features].values\n",
    "labels = supergrouped_variable_df['cluster'].values\n",
    "\n",
    "# Fit UMAP\n",
    "# Apply UMAP to reduce 64 dimensions to 2D\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=30,        # Numbers of neighbours\n",
    "    min_dist=0.0,          # Allow points to be closer together\n",
    "    n_components=2,        # Reduce to 2D for visualsation\n",
    "    random_state=508,       # For reproducible results\n",
    "    metric='cosine',       # Cosine similarity \n",
    "    init='random',         # Use random initialisation\n",
    "    n_epochs=500,          # More epochs for better convergence\n",
    "    spread=1.0,            # Controls how tightly points are packed\n",
    "    verbose=False          # Show progress\n",
    ")\n",
    "\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "umap_results = pd.DataFrame({\n",
    "    'UMAP1': embedding[:, 0],\n",
    "    'UMAP2': embedding[:, 1],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "# Save the UMAP results\n",
    "umap_results.to_parquet('outputs/umap_results.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| out.width: \"100%\"\n",
    "# Define colours for each cluster - same as earlier map\n",
    "colours = {\n",
    "    \"A\": '#8dd3c7',\n",
    "    \"B\": '#ffffb3',\n",
    "    \"C\": '#bebada',\n",
    "    \"D\": '#fb8072',\n",
    "    \"E\": '#fdb462',\n",
    "    \"F\": \"#235477\",\n",
    "    \"G\": '#fccde5',\n",
    "    \"H\": '#d9d9d9',\n",
    "    \"I\": '#bc80bd',\n",
    "    \"J\": '#ccebc5'\n",
    "}\n",
    "\n",
    "# Create interactive UMAP scatter plot\n",
    "fig_interactive = px.scatter(\n",
    "    umap_results,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='Cluster',\n",
    "    category_orders={\"Cluster\": sorted(umap_results[\"Cluster\"].unique())},  #\n",
    "    color_discrete_map=colours,  \n",
    ")\n",
    "\n",
    "# Style tweaks\n",
    "fig_interactive.update_traces(marker=dict(size=3, opacity=0.7))\n",
    "fig_interactive.update_layout(\n",
    "    title=\"UMAP Projection of Clusters\",\n",
    "    xaxis_title=\"UMAP 1\",\n",
    "    yaxis_title=\"UMAP 2\",\n",
    "    legend_title=\"Cluster\"\n",
    ")\n",
    "\n",
    "#save to html\n",
    "fig_interactive.write_html(\"outputs/umap_interactive.html\")\n",
    "# fig_interactive.update_layout(width=800, height=600)\n",
    "fig_interactive.show(config={\"responsive\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UMAP projection shows there is reasonable separation between the clusters, indicating that the k-means clustering has identified distinct groups in the data.\n",
    "In particular the small cluster in the bottom left which represents the city centre in our case study of Liverpool, is well-defined and separated from other clusters.\n",
    "\n",
    "There are indications of further structure within clusters, which could be explored further using hierarchical clustering to subdivide clusters into subclusters.\n",
    "More on that in a bit.. for now lets dig into the clusters that we've got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Profiling, Naming, and Describing using Language Models\n",
    "\n",
    "We can explore the characteristics of each cluster using summary statistics and index scores. This helps us understand each cluster.\n",
    "\n",
    "## Cluster Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lot at the characteristics of each cluster\n",
    "\n",
    "# Read in the data\n",
    "pop_size = pd.read_csv(\"input_data/oa_pop_data.csv\")\n",
    "pop_size = pop_size.set_index('OA')\n",
    "#rename column to \"population\"\n",
    "pop_size = pop_size.rename(columns={'uk001001': 'population'})\n",
    "pop_size = pop_size['population']\n",
    "\n",
    "#basic statistics of each cluster, number (perc of OAs) in each cluster and population\n",
    "\n",
    "#number of OAs in each cluster\n",
    "cluster_counts = supergrouped_variable_df['cluster'].value_counts().sort_index()\n",
    "#percentage of OAs in each cluster\n",
    "cluster_perc = (cluster_counts / cluster_counts.sum() * 100).round(2)\n",
    "\n",
    "#join pop_size to supergrouped_variable_df on index\n",
    "supergrouped_variable_df_withpop = supergrouped_variable_df.join(pop_size, how='left')\n",
    "\n",
    "#pop in each cluster\n",
    "cluster_pop = supergrouped_variable_df_withpop.groupby('cluster')['population'].sum()\n",
    "#percentage of pop in each cluster\n",
    "cluster_pop_perc = (cluster_pop / cluster_pop.sum() * 100).round(2)\n",
    "\n",
    "#combine into a dataframe\n",
    "cluster_summary = pd.DataFrame({\n",
    "    'Number of OAs': cluster_counts,\n",
    "    'Percentage of OAs': cluster_perc,\n",
    "    'Population': cluster_pop,\n",
    "    'Percentage of Population': cluster_pop_perc\n",
    "})\n",
    "cluster_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Profiling\n",
    "\n",
    "Index scores are a way to summarise how a particular variable behaves within a cluster compared to the overall average. They help identify which characteristics are over- or under-represented in each cluster.\n",
    "\n",
    "Index scores are calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{Index Score} = \\left( \\frac{\\text{Mean of Variable in Cluster}}{\\text{Overall Mean of Variable}} \\right) \\times 100\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **Mean of Variable in Cluster**: the average value of the variable for all areas within the specific cluster.  \n",
    "- **Overall Mean of Variable**: the average value of the variable across all areas in the dataset.  \n",
    "\n",
    "Here we will look only at variables used in the clustering. It can also be useful to look at variables not used in the clustering or from other data sources to help understand the clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map encoding -> human name\n",
    "encoding_to_name = dict(zip(var_lookup[\"No.\"], var_lookup[\"Variable_Name\"]))\n",
    "\n",
    "features = [c for c in supergrouped_variable_df.columns if c != 'cluster']\n",
    "#dont average the cluster column\n",
    "cluster_means = supergrouped_variable_df.groupby('cluster').mean()\n",
    "global_means = supergrouped_variable_df[features].mean()\n",
    "global_stds = supergrouped_variable_df[features].std()\n",
    "\n",
    "# --- Calculate percentage difference ---\n",
    "pct_diff = (cluster_means / global_means) * 100\n",
    "#drop columns with nan\n",
    "pct_diff = pct_diff.dropna(axis=1, how='any')\n",
    "pct_display_df = pct_diff.T  # index: encodings\n",
    "\n",
    "\n",
    "# --- Calculate percentage difference ---\n",
    "pct_diff = (cluster_means / global_means) * 100\n",
    "#drop columns with nan\n",
    "pct_diff = pct_diff.dropna(axis=1, how='any')\n",
    "pct_display_df = pct_diff.T  # index: encodings\n",
    "\n",
    "# build customdata for hover (human names repeated across clusters)\n",
    "human_names = pct_display_df.index.map(lambda e: encoding_to_name.get(e, e)).values\n",
    "customdata_pct = np.tile(human_names.reshape(-1, 1), (1, pct_display_df.shape[1]))\n",
    "\n",
    "# get symmetric range around 100\n",
    "max_abs = np.nanmax(np.abs(pct_display_df.values - 100))\n",
    "\n",
    "# --- Heatmap (percentage difference) ---d\n",
    "fig_pct = px.imshow(\n",
    "    pct_display_df,\n",
    "    color_continuous_scale=\"RdYlGn\",\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    "    labels=dict(x=\"Cluster\", y=\"Feature (encoding)\", color=\"% of global mean\"),\n",
    "    zmin=0,\n",
    "    zmax=200\n",
    ")\n",
    "\n",
    "# attach customdata and set hover\n",
    "fig_pct.data[0].customdata = customdata_pct\n",
    "fig_pct.update_traces(\n",
    "    hovertemplate=\"Cluster: %{x}<br>Encoding: %{y}<br>Name: %{customdata}<br>% of Global Mean: %{z:.1f}%<extra></extra>\",\n",
    "    zmid=100  # centre colours on 100%\n",
    ")\n",
    "\n",
    "fig_pct.update_layout(\n",
    "    title=\"Cluster Profiles (% of Global Mean)\",\n",
    "    xaxis_title=\"Cluster\",\n",
    "    yaxis_title=\"Feature (encoding)\",\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig_pct.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Cluster Naming (and description)\n",
    "\n",
    "To create a useful geodemographic classification, we need to assign meaningful names and descriptions to each cluster. This helps in interpreting the clusters and communicating their characteristics effectively.  \n",
    "Traditionally, this is done manually by examining the statistical profiles of each cluster (often with input (as we produced) sometimes with external ) and using domain knowledge to assign names. Either done by a single expert, panel or utilising crowd sourcing approaches. Either way it is a time consuming process. However, we can leverage Large Language Models (LLMs) to assist in this process. We have demonstrated that LLMs can be used to generate initial name and description suggestions based on the statistical profiles of each cluster [@llmpaper].  \n",
    "We can use LLMs to generate initial name and description suggestions based on the statistical profiles of each cluster.  \n",
    "Again here we are using only the variables used in the clustering. It can also be useful to include other variables or external data to provide more context for the LLM.\n",
    "\n",
    "### Using the OpenAI API  \n",
    "Below I use the OpenAI API, if you have an API key insert it in an .env file^[.env files are files that contain environment variables, they can be created as a plain text file (named .env) in the root directory. These files often contain private information so should not be commited to git] as\n",
    "OPENAI_API_KEY=\"sk....sA\"\n",
    "\n",
    "**If you do have an API key skip the next cell and go to the cell where we will use a browser prompt to get the cluster names and descriptions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "#| echo: true\n",
    "#| output: true\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # this loads variables from .env into environment\n",
    "\n",
    "#get your OpenAI API key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# -------------------------\n",
    "# JSON Schema for output\n",
    "# -------------------------\n",
    "cluster_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"description\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"name\", \"description\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"You are a geodemographic analyst. \n",
    "Your task is to produce commercial-style geodemographic cluster pen portraits \n",
    "and cluster names.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "A geodemographics company is trying to explain the characteristics of several \n",
    "neighborhoods to a new customer. They present data comparing each \n",
    "neighborhood to the region average. A score of 100 means the neighborhood \n",
    "is equivalent to the regional average, 150 means one and a half times, 200 means twice, 50 means half, \n",
    "and 300 means three times the regional average. \n",
    "\n",
    "The description of each neighborhood should focus on characteristics with scores above 120 or below 80. \n",
    "Write in the third person, no more than 500 words. \n",
    "Do not mention the specific scores. Instead, describe patterns relative to the regional average (above/below). \n",
    "\n",
    "In the style of a commercial geodemographic classification, create a cluster name that summarises the pen portrait. \n",
    "The name should capture as many different characteristics as possible and be no more than 3 words.\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# Loop through clusters\n",
    "# -------------------------\n",
    "cluster_summaries = {}\n",
    "for cluster in pct_diff.index:\n",
    "    cluster_pct = pct_diff.loc[cluster]\n",
    "\n",
    "    cluster_data = {\n",
    "        \"cluster\": cluster,\n",
    "        \"data\": {\n",
    "            encoding_to_name.get(feature, feature): round(value, 1)\n",
    "            for feature, value in cluster_pct.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.strip()},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(cluster_data)},\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"name\": \"cluster_summary\",\n",
    "                \"schema\": cluster_schema,\n",
    "                \"strict\": True,\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    cluster_summary = json.loads(response.output_text)\n",
    "\n",
    "    # store under your cluster ID\n",
    "    cluster_summaries[cluster] = cluster_summary\n",
    "\n",
    "cluster_summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for Browser Based LLM\n",
    "The follow code cell generates a prompt for to be used in an LLM of your choice.\n",
    "Try it in your browser based LLM of choice (e.g. chatGPT, Claude, Gemini, etc)\n",
    "\n",
    "The prompt should insure that the LLM produses the output in the correct format but this cannot beguaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the prompt to copy and paste into a LLM to generate cluster descriptions\n",
    "\n",
    "prompt_intial = \"\"\"\n",
    "A geodemographics company is trying to explain the characteristics of several neighbourhoods to a new customer. \n",
    "They present data comparing each neighbourhood to the region average. \n",
    "A score of 100 means the neighbourhood is equivalent to the national average, \n",
    "a score of 150 means the neighbourhood is one and a half times the national average, \n",
    "a score of 200 means the neighbourhood is twice the national average, \n",
    "a score of 50 means the neighbourhood is half of the region average, \n",
    "a score of 300 means the neighbourhood is three times the region average. \n",
    "\n",
    "Each neighbourhood has the following characteristics, described in #DATA# below. \n",
    "Data are presented for each characteristic followed by a colon, and then a score. \n",
    "The description of each neighbourhood should focus on characteristics that have scores which are greater than 120 or less than 80.\n",
    "Write a separate description for each cluster (Cluster A, Cluster B, Cluster C, Cluster D, etc. \n",
    "Each description should be written in the third person, in no more than 500 words. Do not mention the specific scores from the #DATA#. \n",
    "Instead, use descriptive words to illustrate rates that are above or below the regional average.\n",
    "Make comparisons to the regional average, do not talk in absolute terms.\n",
    "\"\"\"\n",
    "\n",
    "prompt_data =\"\"\n",
    "# print the index scores for each cluster in this format:\n",
    "\n",
    "for cluster in pct_diff.index:\n",
    "    prompt_data += f\"\\n#DATA# cluster_key: {cluster}\\n\"\n",
    "    cluster_pct = pct_diff.loc[cluster]\n",
    "    for feature, value in cluster_pct.items():\n",
    "        feature_name = encoding_to_name.get(feature, feature)\n",
    "        prompt_data += f\"{feature_name}: {value:.1f}\\n\"\n",
    "\n",
    "prompt_struc = \"\"\"\n",
    "In the style of a commercial geodemographic classification; create a cluster name \n",
    "that would summarise the created geodemographic pen portraits. The names should capture as many \n",
    "different characteristics contained within the description as possible. \n",
    "The cluster name should be no more than 3 words.\n",
    "Return your response in JSON format with the structure: {\"cluster_key_1\": {\"name\": \"\", \"description\": \"\"},\"cluster_key_2\": {\"name\": \"\", \"description\": \"\"},...}\"\"\"\n",
    "\n",
    "full_prompt = prompt_intial + prompt_data + prompt_struc\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the result in here;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summaries = {\n",
    "  \"A\": {\n",
    "    \"name\": \"Established Professional Residents\",\n",
    "    \"description\": \"This neighbourhood is characterised by an older demographic profile, with notably higher proportions of residents aged sixty-five and over, particularly those aged eighty-five and above who are represented at considerably elevated levels compared to the regional average. The area has a markedly high concentration of residents living in communal establishments, appearing at more than twice the regional rate. Housing stock is distinctively skewed towards flats, maisonettes, and apartments, which feature at substantially elevated levels, while detached properties also appear somewhat above the regional norm. The residential population shows a strong presence of one-person households, appearing at moderately elevated levels. The neighbourhood demonstrates an established, relatively settled character, with residents predominantly UK-born and overwhelmingly from a single ethnic background. The Black population is notably underrepresented, appearing at substantially lower levels than the regional average, while residents who cannot speak English well or at all are also significantly below regional norms. The area exhibits a professional character, with managers, directors, senior officials, and professional occupations represented at moderately elevated levels. Educational attainment leans towards higher qualifications, with Level 4 qualifications and above appearing at notably higher rates. Residents are more likely to be married or in registered civil partnerships, and somewhat more likely to be separated or divorced than the regional average. The neighbourhood shows lower proportions of families with dependent children and younger age groups, particularly those under five, who appear at moderately reduced levels. Despite the professional occupational profile, full-time students are somewhat underrepresented, and unemployment appears at lower levels than the region. The area has moderately elevated rates of private rental accommodation alongside ownership, suggesting a mixed tenure profile that accommodates both established homeowners and professional renters.\"\n",
    "  },\n",
    "  \"B\": {\n",
    "    \"name\": \"Multicultural Urban Families\",\n",
    "    \"description\": \"This neighbourhood stands out for its remarkable ethnic diversity, with substantially elevated representation across multiple minority ethnic groups. Pakistani, Black, Bangladeshi, and Other Asian populations all appear at considerably higher levels than the regional average, with some groups represented at nearly three times the regional rate. Chinese and Indian populations are also present at notably elevated levels, while the White population is moderately below the regional average. This diversity is reflected in the country of birth data, with residents born in Africa appearing at more than twice the regional rate, and those from both EU and non-EU European countries substantially overrepresented. The neighbourhood faces significant linguistic challenges, with residents who cannot speak English well or at all appearing at nearly three times the regional rate. The area has a younger demographic profile, with children under five represented at moderately elevated levels, while older residents, particularly those aged eighty-five and over, appear at substantially reduced rates. The housing landscape is dominated by terraced houses and flats, both appearing at considerably elevated levels, while detached and semi-detached properties are somewhat underrepresented. Social rented accommodation features prominently at substantially higher rates, alongside moderately elevated private rental levels, while ownership rates fall notably below the regional average. Vehicle ownership is considerably lower, with households having two or more cars appearing at substantially reduced levels. The occupational structure skews towards elementary occupations, which appear at moderately elevated rates, while managers, directors, and senior officials are somewhat underrepresented. Unemployment appears at considerably higher levels than the regional average. The neighbourhood shows elevated proportions of part-time workers and full-time students. Despite the diverse population, families with dependent children appear at levels close to the regional average, while one-person households are moderately elevated. Religious adherence is notable, with followers of non-Christian religions appearing at moderately elevated levels.\"\n",
    "  },\n",
    "  \"C\": {\n",
    "    \"name\": \"Working Family Terraces\",\n",
    "    \"description\": \"This neighbourhood presents a working-class character with a predominantly UK-born, White population that closely mirrors regional averages. The area is notably less diverse than the region, with most minority ethnic groups substantially underrepresented, particularly Pakistani populations who appear at less than half the regional rate. Black, Bangladeshi, Chinese, and Indian populations are all present at considerably reduced levels. Residents born in Africa, non-EU Europe, and EU countries all appear at notably lower rates than the regional average. The demographic profile shows a family-oriented character, with children under five and those aged five to fourteen both appearing at moderately elevated levels, while residents aged eighty-five and over are present at somewhat reduced rates. Families with dependent children feature at moderately higher levels than the region. The housing stock is heavily weighted towards terraced properties, which appear at substantially elevated rates, while detached houses and flats are both considerably underrepresented. Social rented accommodation is present at considerably elevated levels, while ownership rates remain close to regional norms. The communal establishment population is dramatically underrepresented, appearing at nearly half the regional rate. The neighbourhood's occupational profile reveals a working-class character, with elementary occupations, process plant and machine operatives, sales and customer service occupations, and caring service occupations all appearing at moderately elevated levels. Conversely, managers, directors, senior officials, and professional occupations are both somewhat underrepresented. Educational attainment trends lower, with Level 4 qualifications considerably below regional rates, while Level 1-2 qualifications appear at moderately elevated levels. Unemployment is present at moderately higher rates than the regional average. The area shows relative residential stability, with most residents living at the same address as one year prior, and households predominantly comprising members from the same ethnic group.\"\n",
    "  },\n",
    "  \"D\": {\n",
    "    \"name\": \"Student Cosmopolitan Flats\",\n",
    "    \"description\": \"This neighbourhood exhibits a distinctly transient, young adult character, overwhelmingly dominated by residents living in communal establishments at more than five times the regional rate. The area shows a dramatic absence of children and older residents, with those aged under five appearing at less than two-thirds the regional rate, those aged five to fourteen at less than half, and those aged eighty-five and over at roughly one-quarter of regional levels. Middle-aged residents are also considerably underrepresented. The population is remarkably diverse and internationally oriented, with residents born outside the UK substantially overrepresented. Those born in non-EU European countries appear at more than three times the regional rate, while African and EU-born residents are also present at considerably elevated levels. UK-born residents are notably underrepresented. This international character is reflected in exceptional ethnic diversity, with Pakistani, Indian, Chinese, Black, Bangladeshi, Other Asian, and Mixed ethnic group populations all appearing at substantially elevated levels, many at roughly three times the regional rate. The White population is moderately below regional averages. Language barriers are significant, with residents who cannot speak English well or at all appearing at roughly twice the regional rate. Full-time students are present at substantially elevated rates, nearly one and a half times the regional average, explaining much of the neighbourhood's character. The housing stock is dominated by flats, maisonettes, and apartments at more than twice the regional rate, while traditional houses—detached, semi-detached, and terraced—are all dramatically underrepresented. Private rental accommodation is substantially elevated, while ownership rates are notably below regional levels. The area shows high residential turnover, with residents far less likely to be living at the same address as one year prior. Educational qualifications trend higher, with Level 3 and particularly Level 4 qualifications above regional rates, while lower-level qualifications are substantially underrepresented. Professional occupations appear at moderately elevated levels, while skilled trades and process plant operatives are considerably below regional averages. Never-married individuals are substantially overrepresented, while married couples and families with dependent children appear at considerably reduced rates.\"\n",
    "  },\n",
    "  \"E\": {\n",
    "    \"name\": \"Suburban Family Homeowners\",\n",
    "    \"description\": \"This neighbourhood represents an affluent, predominantly White British suburban character. The population is overwhelmingly UK-born, with residents from EU countries, non-EU Europe, and Africa all appearing at substantially reduced levels compared to the regional average. Ethnic diversity is notably low, with Black populations present at less than half the regional rate, and Pakistani, Bangladeshi, Other Asian, and Mixed ethnic group populations all considerably underrepresented. Language barriers are virtually absent, with residents who cannot speak English well or at all appearing at roughly one-third of the regional rate. The area exhibits strong ethnic homogeneity, with households where all members share the same ethnic group appearing at moderately elevated levels. The demographic profile skews slightly older, with residents aged sixty-five to eighty-four and those aged eighty-five and over both appearing at moderately elevated rates. The housing landscape is characterised by owner-occupation at moderately elevated levels, with detached houses substantially overrepresented and semi-detached properties also appearing above regional averages. Conversely, terraced houses appear at less than half the regional rate, while flats are dramatically underrepresented at roughly one-third of regional levels. Social rented accommodation is substantially below regional averages, as is private rental accommodation. The area demonstrates affluence through vehicle ownership, with households possessing two or more cars appearing at moderately elevated rates. The occupational structure reflects professional and managerial employment, with managers, directors, senior officials, professional occupations, and associate professional and technical occupations all appearing at moderately elevated levels. Elementary occupations are somewhat underrepresented. Educational attainment is strong, with Level 4 qualifications and above appearing at moderately elevated rates. Employment rates are favourable, with unemployment substantially below regional levels at roughly three-quarters of the regional rate. The neighbourhood shows a family-oriented character, with married couples moderately overrepresented and never-married individuals somewhat underrepresented. Families with no children appear at moderately elevated levels. One-person households and communal establishment residents are both substantially below regional averages, reinforcing the family-oriented suburban character.\"\n",
    "  }\n",
    "}\n",
    "cluster_descriptions_df = pd.DataFrame.from_dict(cluster_summaries, orient='index')\n",
    "\n",
    "\n",
    "#pretty print the descriptions (break lines for readability)\n",
    "for cluster, row in cluster_descriptions_df.iterrows():\n",
    "    print(f\"Cluster {cluster} - {row['name']}:\\n\")\n",
    "    description = row['description']\n",
    "    #break into lines of max 80 characters\n",
    "    import textwrap\n",
    "    wrapped_description = textwrap.fill(description, width=70)\n",
    "    print(wrapped_description, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the LLM generated names and descriptions are a very useful starting point, it is important to review the outputs carefully both for accuracy, and that they make sense in the context of your specific region and purpose. \n",
    "Any use of LLMs in a production context would need to invove a human in the loop to review the outputs and a ground truthing exercise to ensure the outputs are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "Lets save the results to file for use in GIS software or to format for sharing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_descriptions_df.to_csv(\"outputs/cluster_descriptions.csv\")\n",
    "gdf = oas_region.merge(supergrouped_variable_df, left_index=True, right_index=True, how='left')\n",
    "#save to gpkg\n",
    "gdf.to_file(\"outputs/clustered_geodataframe.gpkg\", layer=\"clusters\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Subclustering\n",
    "\n",
    "We often want to perform a finer level of clustering to capture more detailed patterns in the data.\n",
    "For OAC the top level \"supergroup\" clusters are split further into groups and subgroups by applying the above process iteratively. This process is referred to as top down clustering. This has the advantage of allowing more clusters to be created without needing to consider all clusters at once. It also allows for more interpretable clusters as the subclusters are nested within the broader supergroup clusters.\n",
    "\n",
    "## Selecting the Number of Subclusters\n",
    "We can use clustergrams again to select the number of subclusters for each supergroup.\n",
    "We create clustergrams for each supergroup and select the number of subclusters based on the same principles as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subcluster_clustergrams(output_df, num_clusters, n_init=1):\n",
    "    \"\"\"\n",
    "    Generate and save clustergrams for each supercluster.\n",
    "    This function loops through the existing clusters and creates a clustergram \n",
    "    for each\n",
    "    Parameters:\n",
    "    output_df (pd.DataFrame): DataFrame containing cluster assignments.\n",
    "    num_clusters (int): The total number of clusters to iterate over.\n",
    "    n_init (int, optional): Number of times K-means runs with different centroid seeds.\n",
    "                            Defaults to 1 for quick testing.\n",
    "\n",
    "    \"\"\"\n",
    "    save_dir = \"outputs/plots\" #directory to save the clustergrams\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure save directory exists\n",
    "    cluster_labels = np.sort(output_df[\"cluster\"].unique())\n",
    "    print(cluster_labels)\n",
    "    for cluster_label in cluster_labels:\n",
    "        # Select rows corresponding to the current cluster, dropping the 'cluster' column\n",
    "        cluster_df = output_df.query(\"cluster == @cluster_label\").drop(columns='cluster')\n",
    "\n",
    "        print(f\"Cluster: {cluster_label,cluster_summaries[cluster_label]['name']}, {len(cluster_df)} geographies in cluster\")\n",
    "\n",
    "        if cluster_df.empty:\n",
    "            print(f\"Skipping cluster {cluster_label} as it has no data.\")\n",
    "            continue\n",
    "\n",
    "        # Define save location\n",
    "        save_loc = os.path.join(save_dir, f\"subcluster_clustergram_cluster{cluster_label}.png\")\n",
    "        print(f\"Saving clustergram to {save_loc}\")\n",
    "\n",
    "        # Generate clustergram\n",
    "        cgram_sub = Clustergram(range(1, 10), n_init=n_init, random_state=random_seed,verbose=False)\n",
    "        cgram_sub.fit(cluster_df)  # Fit model to data\n",
    "        cgram_sub.plot()  # Generate plot\n",
    "        plt.suptitle(f\"Clustergram for Cluster {cluster_label} - {cluster_summaries[cluster_label]['name']}\")\n",
    "        plt.savefig(save_loc)  # Save figure\n",
    "        plt.show()  # Display plot\n",
    "\n",
    "# Example usage\n",
    "create_subcluster_clustergrams(supergrouped_variable_df, num_clusters, n_init=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the subclustering \n",
    "We can now select the number of subclusters to split each of the supergroups into using the clustergrams above.\n",
    "The length of the list must match num_clusters (the number of supergroups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcluster_nums = [3, 3, 4, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_subclustering(input_df: pd.DataFrame, subcluster_nums: list, num_clusters: int, n_init: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs subclustering for each supergroup using KMeans and returns a modified DataFrame with subcluster labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - output_df (pd.DataFrame): The original DataFrame containing data and cluster assignments.\n",
    "    - subcluster_nums (list): A list specifying the number of subclusters to split each supergroup into.\n",
    "    - num_clusters (int): The total number of supergroups.\n",
    "    - n_init (int, optional): The number of times KMeans will be initialized. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A new the output dataFrame with an added 'subcluster' column.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_labels = np.sort(input_df[\"cluster\"].unique())\n",
    "    print(f\"Cluster labels found: {cluster_labels}\")\n",
    "    if len(subcluster_nums) != len(cluster_labels):\n",
    "        raise ValueError(f\"Length of subcluster_nums ({len(subcluster_nums)}) does not match num_clusters ({len(cluster_labels)}).\")\n",
    "\n",
    "    # Work on a copy of the DataFrame to prevent unintended modifications\n",
    "    df = input_df.copy()\n",
    "\n",
    "    for cluster, num_subclusters in zip(cluster_labels, subcluster_nums):\n",
    "        print(f\"Clustering supergroup {cluster,cluster_summaries[cluster]['name']} into {num_subclusters} subclusters.\")\n",
    "\n",
    "        # Select rows corresponding to the current cluster, drop the cluster column before clustering\n",
    "        cluster_df = input_df.query(\"cluster == @cluster\").drop(columns='cluster').copy()\n",
    "        # Run KMeans clustering for the selected supergroup\n",
    "        subcluster_output_df = cluster_df.copy()\n",
    "        kmeans_sub = KMeans(n_clusters=num_subclusters, init=\"random\", random_state=random_seed, n_init=n_init)\n",
    "        subcluster_output_df['cluster'] = kmeans_sub.fit_predict(cluster_df)\n",
    "\n",
    "        # Combine names\n",
    "        subcluster_output_df['subcluster'] = [str(cluster) + str(i) for i in subcluster_output_df['cluster']]\n",
    "\n",
    "        # Update the modified DataFrame with subclustering results\n",
    "        df.loc[cluster_df.index, 'subcluster'] = subcluster_output_df['subcluster']\n",
    "\n",
    "    # Save the final output\n",
    "    df.to_csv(\"outputs/subgroups_clusteroutput.csv\")\n",
    "    print(\"Final output saved to outputs/subgroups_clusteroutput.csv\")\n",
    "\n",
    "    return df  # Return the modified DataFrame with clusters and subclusters\n",
    "\n",
    "subgrouped_variable_df = run_subclustering(supergrouped_variable_df, subcluster_nums, num_clusters=num_clusters, n_init=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate percentage difference (subclusters vs cluster means) ---\n",
    "\n",
    "# cluster means for reference\n",
    "cluster_means = subgrouped_variable_df.groupby(\"cluster\").mean(numeric_only=True)\n",
    "global_means = subgrouped_variable_df[features].mean()\n",
    "# subcluster means\n",
    "subcluster_means = subgrouped_variable_df.groupby([\"cluster\", \"subcluster\"]).mean(numeric_only=True)\n",
    "\n",
    "# percentage difference: subcluster relative to parent cluster\n",
    "pct_diff_sub = (subcluster_means / cluster_means) * 100\n",
    "pct_diff_sub = (subcluster_means/ global_means)*100\n",
    "pct_display_df_sub = pct_diff_sub.T  # index = features (encodings), columns = MultiIndex (cluster, subcluster)\n",
    "#replace the column MultiIndex with a single level index with \"cluster-subcluster\" format and swap in the cluster names from cluster_summaries\n",
    "pct_display_df_sub.columns = [f\"{cluster_summaries[c[0]]['name']}-{c[1]}\" for c in pct_display_df_sub.columns]\n",
    "\n",
    "\n",
    "\n",
    "# build customdata for hover (human names repeated across cluster–subcluster combos)\n",
    "human_names = pct_display_df_sub.index.map(lambda e: encoding_to_name.get(e, e)).values\n",
    "customdata_pct_sub = np.tile(human_names.reshape(-1, 1), (1, pct_display_df_sub.shape[1]))\n",
    "\n",
    "# get symmetric range around 100\n",
    "max_abs_sub = np.nanmax(np.abs(pct_display_df_sub.values - 100))\n",
    "\n",
    "# --- Heatmap (percentage difference: subcluster vs cluster mean) ---\n",
    "fig_pct_sub = px.imshow(\n",
    "    pct_display_df_sub,\n",
    "    color_continuous_scale=\"RdYlGn\",\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    "    labels=dict(x=\"Subcluster\", y=\"Feature (encoding)\", color=\"% of cluster mean\"),\n",
    "    zmin=0,\n",
    "    zmax=200\n",
    ")\n",
    "\n",
    "# attach customdata and set hover\n",
    "fig_pct_sub.data[0].customdata = customdata_pct_sub\n",
    "fig_pct_sub.update_traces(\n",
    "    hovertemplate=\"Subcluster: %{x}<br>Encoding: %{y}<br>Name: %{customdata}<br>% of Cluster Mean: %{z:.1f}%<extra></extra>\",\n",
    "    zmid=100  # centre colours on 100%\n",
    ")\n",
    "\n",
    "fig_pct_sub.update_layout(\n",
    "    title=\"Subcluster Profiles (% of Cluster Mean)\",\n",
    "    xaxis_title=\"Subcluster\",\n",
    "    yaxis_title=\"Feature (encoding)\",\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# get mapping of column → cluster\n",
    "col_clusters = [col.split(\"-\")[0] for col in pct_display_df_sub.columns]\n",
    "\n",
    "# find where cluster changes (between adjacent columns)\n",
    "boundaries = [\n",
    "    i + 0.5 for i in range(len(col_clusters) - 1)\n",
    "    if col_clusters[i] != col_clusters[i + 1]\n",
    "]\n",
    "\n",
    "# add vertical lines at these boundaries\n",
    "for b in boundaries:\n",
    "    fig_pct_sub.add_vline(\n",
    "        x=b, line_width=2, line_dash=\"dash\", line_color=\"black\"\n",
    "    )\n",
    "\n",
    "fig_pct_sub.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results to file for use in GIS software or to format for sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the geometry column from oas_region to subgrouped_variable_df to make a geodataframe\n",
    "gdf = oas_region.merge(subgrouped_variable_df  , left_index=True, right_index=True, how='left')\n",
    "#save to file\n",
    "gdf.to_file(\"outputs/subclusters_geodataframe.gpkg\", layer='subclusters', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the Subclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| echo: false\n",
    "\n",
    "#code to enable kepler in colab\n",
    "from IPython.display import Javascript\n",
    "display(Javascript('''\n",
    "  google.colab.widgets.installCustomManager('https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/6a14374f468a145a/manager.min.js');\n",
    "'''))\n",
    "\n",
    "# Custom cluster colours for subclusters\n",
    "def generate_shades(hex_color, n_shades=5, step=0.15):\n",
    "    \"\"\"Generate shades centred around a base color.\"\"\"\n",
    "    base = np.array(mcolors.to_rgb(hex_color))\n",
    "    mid = n_shades // 2\n",
    "    shades = []\n",
    "    for i in range(n_shades):\n",
    "        factor = 1 + (i - mid) * step\n",
    "        shade = np.clip(base * factor, 0, 1)\n",
    "        shades.append(mcolors.to_hex(shade))\n",
    "    return shades\n",
    "\n",
    "#same as before \n",
    "base_colors = {\n",
    "    \"A\": '#8dd3c7',\n",
    "    \"B\": '#ffffb3',\n",
    "    \"C\": '#bebada',\n",
    "    \"D\": '#fb8072',\n",
    "    \"E\": '#fdb462',\n",
    "    \"F\": \"#235477\",\n",
    "    \"G\": '#fccde5',\n",
    "    \"H\": '#d9d9d9',\n",
    "    \"I\": '#bc80bd',\n",
    "    \"J\": '#ccebc5'\n",
    "}\n",
    "\n",
    "# Generate subgroup colours\n",
    "colors = {}\n",
    "for (group, hex_color), n_sub in zip(base_colors.items(), subcluster_nums):\n",
    "    shades = generate_shades(hex_color, n_shades=n_sub)\n",
    "    for i, shade in enumerate(shades, start=1):\n",
    "        colors[f\"{group}{i}\"] = shade\n",
    "\n",
    "\n",
    "sorted_clusters = sorted(colors.keys())\n",
    "color_list = [colors[k] for k in sorted_clusters]\n",
    "\n",
    "# # Ensure cluster column is string for Kepler\n",
    "# supergrouped_variable_df[\"cluster\"] = supergrouped_variable_df[\"cluster\"].astype(str)\n",
    "# #append geometry column from oas_liv to supergrouped_variable_df to make a geodataframe\n",
    "gdf = oas_region.merge(subgrouped_variable_df  , left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "# Config for polygons (fill only, no stroke)\n",
    "config = {\n",
    "    \"version\": \"v1\",\n",
    "    \"config\": {\n",
    "        \"visState\": {\n",
    "            \"filters\": [],\n",
    "            \"layers\": [\n",
    "                {\n",
    "                    \"id\": \"clusters_layer\",\n",
    "                    \"type\": \"geojson\",   # polygon layer\n",
    "                    \"config\": {\n",
    "                        \"dataId\": \"clusters\",\n",
    "                        \"label\": \"Clusters\",\n",
    "                        'columns': {'geojson': 'geometry'},\n",
    "                        \"color\": [130, 154, 227],\n",
    "                        \"highlightColor\": [252, 242, 26, 255],\n",
    "                        \"isVisible\": True,\n",
    "                        \"visConfig\": {\n",
    "                            \"opacity\": 0.8,\n",
    "                            \"thickness\": 0,\n",
    "                            \"strokeColor\": None,\n",
    "                            \"colorRange\": {\n",
    "                                \"name\": \"Custom\",\n",
    "                                \"type\": \"qualitative\",\n",
    "                                \"category\": \"Custom\",\n",
    "                                \"colors\": color_list\n",
    "                            },\n",
    "                            \"filled\": True\n",
    "                        },\n",
    "                        \"hidden\": False,\n",
    "                        \"textLabel\": []\n",
    "                    },\n",
    "                    \"visualChannels\": {\n",
    "                        \"colorField\": {\"name\": \"subcluster\", \"type\": \"string\"},\n",
    "                        \"colorScale\": \"ordinal\",\n",
    "                        \"strokeColorField\": None,\n",
    "                        \"strokeColorScale\": \"quantile\",\n",
    "                        \"sizeField\": None,\n",
    "                        \"sizeScale\": \"linear\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"effects\": [],\n",
    "            \"interactionConfig\": {\n",
    "                \"tooltip\": {\n",
    "                    \"fieldsToShow\": {\n",
    "                        \"clusters\": [\n",
    "                            {\"name\": \"subcluster\", \"format\": None}\n",
    "                        ]\n",
    "                    },\n",
    "                    \"enabled\": True\n",
    "                }\n",
    "            },\n",
    "            \"layerBlending\": \"normal\"\n",
    "        },\n",
    "        \"mapState\": {\n",
    "            \"bearing\": 0,\n",
    "            \"dragRotate\": False,\n",
    "               'latitude': centroid_lat,\n",
    "                'longitude': centroid_lon,\n",
    "            \"pitch\": 0,\n",
    "            \"zoom\": 9,\n",
    "            \"isSplit\": False\n",
    "        },\n",
    "        \"mapStyle\": {\n",
    "            \"styleType\": \"dark-matter\",\n",
    "            \"topLayerGroups\": {\n",
    "                \"water\": True,\n",
    "                \"building\": True\n",
    "            },\n",
    "            \"visibleLayerGroups\": {\n",
    "                \"label\": True,\n",
    "                \"road\": True,\n",
    "                \"border\": False,\n",
    "                \"building\": True,\n",
    "                \"water\": True,\n",
    "                \"land\": True,\n",
    "                \"3d building\": False\n",
    "            },\n",
    "            \"mapStyles\": {\n",
    "                \"dark-matter\": {\n",
    "                    \"id\": \"dark-matter\",\n",
    "                    \"label\": \"Carto Dark Matter\",\n",
    "                    \"url\": \"https://basemaps.cartocdn.com/gl/dark-matter-gl-style/style.json\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Show in Kepler\n",
    "map_with_basemap = KeplerGl(data={\"clusters\":gdf}, config=config, height=600)\n",
    "map_with_basemap.save_to_html(file_name=\"outputs/maps/subcluster_map.html\")\n",
    "\n",
    "map_with_basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"outputs/maps/subcluster_map.html\" width=\"100%\" height=\"650\" style=\"border:none;\"></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
